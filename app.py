import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
from pathlib import Path
from gensim.models import Doc2Vec
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="Gá»£i Ã½ cÃ´ng ty tÆ°Æ¡ng tá»± (Doc2Vec)", layout="wide")

# ================================
# Load mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u Doc2Vec
# ================================
@st.cache_resource
def load_doc2vec_and_data():
    df = pd.read_csv("Data/companies_cleaned.csv")
    model = Doc2Vec.load("models/doc2vec_company.model")
    vectors = np.load("models/doc2vec_vectors.npy")
    return df, model, vectors

df_companies, doc2vec_model, doc2vec_vectors = load_doc2vec_and_data()

# ================================
# Load XGBoost Classifier
# ================================
@st.cache_resource
def load_xgboost_classifier():
    with open("saved_models/XGBoost_pipeline.pkl", "rb") as f:
        xgboost_classifier = joblib.load(f)
    return xgboost_classifier

xgboost_classifier = load_xgboost_classifier()

# Stopwords má»Ÿ rá»™ng
stop_words = set([
    "a", "an", "the", "in", "on", "at", "to", "from", "by", "of", "with",
    "and", "but", "or", "for", "nor", "so", "yet",
    "i", "you", "he", "she", "it", "we", "they", "me", "him", "her", "us", "them", "weâ€™re",
    "be", "have", "do", "does", "did", "was", "were", "will", "would", "shall", "should", "may", "might", "can", "could", "must",
    "that", "this", "which", "what", "their", "these", "those", 'https', 'www'
])

# ================================
# Load dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ cÃ´ng ty
# ================================
@st.cache_resource
def load_overview_companies():
    df_overview = pd.read_excel("Data/Overview_Reviews.xlsx")
    return df_overview

df_overview = load_overview_companies()
df = pd.merge(df_companies, df_overview[['id', 'Recommend working here to a friend']], on='id', how='inner')

# ================================
# Táº¡o nhÃ£n phÃ¢n loáº¡i recommend
# ================================
if 'recommend_label' not in df.columns:
    def convert_recommend(value):
        if pd.isna(value) or value.strip() == '0%':
            return 0
        try:
            return 1 if int(value.strip('%')) > 50 else 0
        except:
            return np.nan

    df['recommend_label'] = df['Recommend working here to a friend'].apply(convert_recommend)

# ================================
# Gá»£i Ã½ theo tÃªn cÃ´ng ty
# ================================
def suggest_by_company_name(company_name, top_n=5, industry_filter=None):
    matches = df_companies[df_companies['Company Name'].str.lower().str.contains(company_name.lower())]
    if matches.empty:
        return None, None, None
    idx = matches.index[0]
    vector = doc2vec_vectors[idx]
    sim_scores = cosine_similarity([vector], doc2vec_vectors).flatten()
    sim_scores[idx] = -1

    df_temp = df_companies.copy()
    df_temp["score"] = sim_scores

    if industry_filter:
        df_temp = df_temp[df_temp["Company industry"] == industry_filter]

    top_results = df_temp.sort_values("score", ascending=False).head(top_n)
    return matches.iloc[0]['Company Name'], df_companies.loc[idx]['Company overview'], top_results[['Company Name', 'Company overview', 'score']]

# ================================
# Gá»£i Ã½ theo mÃ´ táº£ ná»™i dung
# ================================
def suggest_by_description(description_text, top_n=5):
    tokens = description_text.lower().split()
    query_vector = doc2vec_model.infer_vector(tokens)
    sim_scores = cosine_similarity([query_vector], doc2vec_vectors)[0]
    top_idx = np.argsort(sim_scores)[::-1][:top_n]
    results = df_companies.loc[top_idx, ['Company Name', 'Company overview']].reset_index(drop=True)
    results['score'] = sim_scores[top_idx]
    return results

# ================================
# Gá»£i Ã½ Ä‘á»‘i tÃ¡c khÃ¡c ngÃ nh
# ================================
def suggest_partners(company_name, top_n=5):
    matches = df_companies[df_companies['Company Name'].str.lower().str.contains(company_name.lower())]
    if matches.empty:
        return None
    idx = matches.index[0]
    industry = df_companies.loc[idx, 'Company industry']
    vector = doc2vec_vectors[idx]
    sim_scores = cosine_similarity([vector], doc2vec_vectors).flatten()
    sim_scores[idx] = -1

    df_temp = df_companies.copy()
    df_temp["score"] = sim_scores
    df_temp = df_temp[df_temp["Company industry"] != industry]
    df_temp = df_temp[df_temp["score"] > 0.6]

    top_partners = df_temp.sort_values("score", ascending=False).head(top_n)
    return top_partners[['Company Name', 'Company industry', 'Company overview', 'score']]

# ================================
# Highlight tá»« tÆ°Æ¡ng tá»±
# ================================
def get_common_keywords(a, b, min_len=4):
    a_words = set(a.lower().split())
    b_words = set(b.lower().split())
    return sorted(list(a_words & b_words - ENGLISH_STOP_WORDS - stop_words), key=lambda x: -len(x))

# ================================
# PhÃ¢n loáº¡i cÃ´ng ty báº±ng XGBoost
# ================================
def predict_recommendation(company_name):
    company_data = df[df['Company Name'].str.lower() == company_name.lower()]
    if company_data.empty:
        return None

    required_columns = ['Company overview', 'Company industry', 'Training & learning', 'Salary & benefits']
    for col in required_columns:
        if col not in company_data.columns:
            company_data[col] = ""
        company_data.loc[:, col] = company_data[col].fillna('')

    company_data.loc[:, required_columns] = company_data[required_columns].replace("", np.nan)

    try:
        company_data['Salary & benefits'] = pd.to_numeric(company_data['Salary & benefits'], errors='coerce')
    except Exception as e:
        print(f"Error converting 'Salary & benefits' to numeric: {e}")

    features = company_data[required_columns]

    try:
        prediction = xgboost_classifier.predict(features)
    except Exception as e:
        print(f"Error during prediction: {e}")
        return "Error in prediction"

    return "Recommend" if prediction == 1 else "Not Recommend"

# ================================
# Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch dá»¯ liá»‡u
# ================================
def plot_recommendation_distribution(df):
    recommendation_counts = df['recommend_label'].value_counts()
    fig, ax = plt.subplots(figsize=(6, 4))
    recommendation_counts.plot(kind='bar', ax=ax, color=['green', 'red'])
    ax.set_title("Tá»· lá»‡ Recommend vs Not Recommend")
    ax.set_xlabel("TÃ¬nh tráº¡ng cÃ´ng ty")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    ax.set_xticklabels(['Not Recommend', 'Recommend'], rotation=0)
    st.pyplot(fig)

def plot_industry_distribution(df):
    plt.figure(figsize=(12, 6))
    ax = sns.countplot(data=df, x='Company industry', hue='recommend_label')
    ax.set_title("Tá»· lá»‡ Recommend theo ngÃ nh", fontsize=16)
    ax.set_xlabel("NgÃ nh cÃ´ng nghiá»‡p", fontsize=12)
    ax.set_ylabel("Sá»‘ lÆ°á»£ng cÃ´ng ty", fontsize=12)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
    plt.tight_layout()
    st.pyplot(plt)

# ================================
# Giao diá»‡n Streamlit
# ================================
st.title("ğŸ¢ Gá»£i Ã½ cÃ´ng ty tÆ°Æ¡ng tá»± (Doc2Vec)")

st.sidebar.header("ğŸ”§ Tuá»³ chá»n")
top_n = st.sidebar.slider("Sá»‘ lÆ°á»£ng cÃ´ng ty gá»£i Ã½", min_value=3, max_value=15, value=5)
industry_list = df['Company industry'].dropna().unique().tolist()
selected_industry = st.sidebar.selectbox("ğŸ“‚ Lá»c theo ngÃ nh", ["-- Táº¥t cáº£ --"] + sorted(industry_list))
industry_filter = None if selected_industry == "-- Táº¥t cáº£ --" else selected_industry

tab1, tab2 = st.tabs(["ğŸ” TÃ¬m theo tÃªn cÃ´ng ty", "âœï¸ TÃ¬m theo mÃ´ táº£"])

# Tab 1: TÃ¬m theo tÃªn cÃ´ng ty
with tab1:
    st.subheader("ğŸ” Nháº­p tÃªn cÃ´ng ty (vÃ­ dá»¥: FPT):")
    company_input = st.text_input("TÃªn cÃ´ng ty")

    if company_input:
        found_name, overview, result_df = suggest_by_company_name(company_input, top_n=top_n, industry_filter=industry_filter)
        if result_df is not None:
            st.success(f"âœ… TÃ¬m tháº¥y: **{found_name}**")
            st.markdown("**ğŸ“„ MÃ´ táº£ cÃ´ng ty:**")
            st.info(overview)

            st.markdown("ğŸ“ˆ **CÃ¡c cÃ´ng ty tÆ°Æ¡ng tá»±:**")
            for _, row in result_df.iterrows():
                common = get_common_keywords(overview, row['Company overview'])
                st.markdown(f"ğŸ”¹ **{row['Company Name']}** â€“ Ä‘iá»ƒm: `{row['score']:.3f}`")
                st.markdown(f"ğŸŸ© Tá»« khÃ³a chung: `{', '.join(common[:10])}`")
                st.markdown("---")

            csv = result_df.to_csv(index=False).encode('utf-8')
            st.download_button("â¬‡ï¸ Táº£i danh sÃ¡ch CSV", csv, f"{found_name}_similar_companies.csv", "text/csv")

            st.subheader("ğŸ¤ Gá»£i Ã½ Ä‘á»‘i tÃ¡c tiá»m nÄƒng (khÃ¡c ngÃ nh)")
            partners = suggest_partners(company_input, top_n=5)
            if partners is not None:
                st.dataframe(partners, use_container_width=True)

            recommendation = predict_recommendation(found_name)
            st.subheader("ğŸ” Káº¿t quáº£ phÃ¢n loáº¡i:")
            st.write(f"CÃ´ng ty **{found_name}** Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ : **{recommendation}**")

            st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch dá»¯ liá»‡u")
            plot_recommendation_distribution(df)
            plot_industry_distribution(df)

# Tab 2: TÃ¬m theo mÃ´ táº£
with tab2:
    st.subheader("âœï¸ Nháº­p mÃ´ táº£ cÃ´ng ty hoáº·c lÄ©nh vá»±c báº¡n muá»‘n tÃ¬m:")
    description_input = st.text_area("VÃ­ dá»¥: CÃ´ng ty pháº§n má»m chuyÃªn vá» trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  dá»¯ liá»‡u lá»›n...")

    if description_input:
        results_desc = suggest_by_description(description_input, top_n=top_n)
        st.subheader("ğŸ“‹ Danh sÃ¡ch gá»£i Ã½ theo mÃ´ táº£:")
        st.dataframe(results_desc, use_container_width=True)

        csv_desc = results_desc.to_csv(index=False).encode('utf-8')
        st.download_button("â¬‡ï¸ Táº£i danh sÃ¡ch CSV", csv_desc, "description_based_suggestions.csv", "text/csv")
