import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
from pathlib import Path
from gensim.models import Doc2Vec
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="Gá»£i Ã½ cÃ´ng ty tÆ°Æ¡ng tá»± (Doc2Vec)", layout="wide")

@st.cache_resource
def load_doc2vec_and_data():
    df = pd.read_csv("Data/companies_cleaned.csv")
    model = Doc2Vec.load("models/doc2vec_company.model")
    vectors = np.load("models/doc2vec_vectors.npy")
    return df, model, vectors

df_companies, doc2vec_model, doc2vec_vectors = load_doc2vec_and_data()

@st.cache_resource
def load_xgboost_classifier():
    with open("models/XGBoost_pipeline.pkl", "rb") as f:
        xgboost_classifier = joblib.load(f)
    return xgboost_classifier

xgboost_classifier = load_xgboost_classifier()

stop_words = set([
    "a", "an", "the", "in", "on", "at", "to", "from", "by", "of", "with",
    "and", "but", "or", "for", "nor", "so", "yet",
    "i", "you", "he", "she", "it", "we", "they", "me", "him", "her", "us", "them", "weâ€™re",
    "be", "have", "do", "does", "did", "was", "were", "will", "would", "shall", "should", "may", "might", "can", "could", "must",
    "that", "this", "which", "what", "their", "these", "those", 'https', 'www'
])

@st.cache_resource
def load_overview_companies():
    df_overview = pd.read_excel("Data/Overview_Reviews.xlsx")
    return df_overview

df_overview = load_overview_companies()
df = pd.merge(df_companies, df_overview[['id', 'Recommend working here to a friend']], on='id', how='inner')

def convert_recommend(value):
    if pd.isna(value) or value.strip() == '0%':
        return 0
    try:
        return 1 if int(value.strip('%')) > 50 else 0
    except:
        return np.nan

if 'recommend_label' not in df.columns:
    df['recommend_label'] = df['Recommend working here to a friend'].apply(convert_recommend)

def suggest_by_company_name(company_name, top_n=5, industry_filter=None):
    matches = df_companies[df_companies['Company Name'].str.lower().str.contains(company_name.lower())]
    if matches.empty:
        return None, None, None
    idx = matches.index[0]
    vector = doc2vec_vectors[idx]
    sim_scores = cosine_similarity([vector], doc2vec_vectors).flatten()
    sim_scores[idx] = -1

    df_temp = df_companies.copy()
    df_temp["score"] = sim_scores

    if industry_filter:
        df_temp = df_temp[df_temp["Company industry"] == industry_filter]

    top_results = df_temp.sort_values("score", ascending=False).head(top_n)
    return matches.iloc[0]['Company Name'], df_companies.loc[idx]['Company overview'], top_results[['Company Name', 'Company overview', 'score']]

def suggest_by_description(description_text, top_n=5):
    tokens = description_text.lower().split()
    query_vector = doc2vec_model.infer_vector(tokens)
    sim_scores = cosine_similarity([query_vector], doc2vec_vectors)[0]
    top_idx = np.argsort(sim_scores)[::-1][:top_n]
    results = df_companies.loc[top_idx, ['Company Name', 'Company overview']].reset_index(drop=True)
    results['score'] = sim_scores[top_idx]
    return results

def suggest_partners(company_name, top_n=5):
    matches = df_companies[df_companies['Company Name'].str.lower().str.contains(company_name.lower())]
    if matches.empty:
        return None
    idx = matches.index[0]
    industry = df_companies.loc[idx, 'Company industry']
    vector = doc2vec_vectors[idx]
    sim_scores = cosine_similarity([vector], doc2vec_vectors).flatten()
    sim_scores[idx] = -1

    df_temp = df_companies.copy()
    df_temp["score"] = sim_scores
    df_temp = df_temp[df_temp["Company industry"] != industry]
    df_temp = df_temp[df_temp["score"] > 0.6]

    top_partners = df_temp.sort_values("score", ascending=False).head(top_n)
    return top_partners[['Company Name', 'Company industry', 'Company overview', 'score']]

def get_common_keywords(a, b, min_len=4):
    a_words = set(a.lower().split())
    b_words = set(b.lower().split())
    return sorted(list(a_words & b_words - ENGLISH_STOP_WORDS - stop_words), key=lambda x: -len(x))

def predict_recommendation(company_name):
    company_data = df[df['Company Name'].str.lower() == company_name.lower()]
    if company_data.empty:
        return None

    required_columns = ['Company overview', 'Company industry', 'Training & learning', 'Salary & benefits']
    for col in required_columns:
        if col not in company_data.columns:
            company_data[col] = ""
        company_data.loc[:, col] = company_data[col].fillna('')

    company_data.loc[:, required_columns] = company_data[required_columns].replace("", np.nan)

    try:
        company_data['Salary & benefits'] = pd.to_numeric(company_data['Salary & benefits'], errors='coerce')
    except Exception as e:
        print(f"Error converting 'Salary & benefits' to numeric: {e}")

    features = company_data[required_columns]

    try:
        prediction = xgboost_classifier.predict(features)
    except Exception as e:
        print(f"Error during prediction: {e}")
        return "Error in prediction"

    return "Recommend" if prediction == 1 else "Not Recommend"

def plot_recommendation_distribution(df):
    recommendation_counts = df['recommend_label'].value_counts()
    fig, ax = plt.subplots(figsize=(6, 4))
    recommendation_counts.plot(kind='bar', ax=ax, color=['green', 'red'])
    ax.set_title("Tá»· lá»‡ Recommend vs Not Recommend")
    ax.set_xlabel("TÃ¬nh tráº¡ng cÃ´ng ty")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    ax.set_xticklabels(['Not Recommend', 'Recommend'], rotation=0)
    st.pyplot(fig)

def plot_industry_distribution(df):
    plt.figure(figsize=(12, 6))
    ax = sns.countplot(data=df, x='Company industry', hue='recommend_label')
    ax.set_title("Tá»· lá»‡ Recommend theo ngÃ nh", fontsize=16)
    ax.set_xlabel("NgÃ nh cÃ´ng nghiá»‡p", fontsize=12)
    ax.set_ylabel("Sá»‘ lÆ°á»£ng cÃ´ng ty", fontsize=12)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
    plt.tight_layout()
    st.pyplot(plt)

st.markdown("""<style>
    .css-1d391kg { font-size: 16px; font-weight: bold; position: fixed; left: 10px; }
    .css-1d391kg-first { bottom: 60px; }
    .css-1d391kg-second { bottom: 30px; }
    .image-container { position: relative; margin-top: 20px; text-align: center; width: 50%; margin-left: auto; margin-right: auto; padding: 0; }
    .image-container img { width: 100%; height: auto; object-fit: cover; margin: 0; padding: 0; }
    .copyright { position: fixed; top: 10px; left: 10px; font-size: 14px; color: grey; }
    .icon { position: fixed; top: 10px; right: 50px; font-size: 24px; color: grey; }
</style>""", unsafe_allow_html=True)

st.title("ğŸ¢ Gá»£i Ã½ cÃ´ng ty tÆ°Æ¡ng tá»± (Doc2Vec)")
st.image('ITViec.jpg', use_container_width=True)
st.markdown('<div class="icon">CopyRight@LeHuuSonHai</div>', unsafe_allow_html=True)

st.sidebar.header("ğŸ”§ TuÃ¬ chá»n")
top_n = st.sidebar.slider("Sá»‘ lÆ°á»£ng cÃ´ng ty gá»£i Ã½", min_value=3, max_value=15, value=5)
industry_list = df['Company industry'].dropna().unique().tolist()
selected_industry = st.sidebar.selectbox("ğŸ“‚ Lá»c theo ngÃ nh", ["-- Táº¥t cáº£ --"] + sorted(industry_list))
industry_filter = None if selected_industry == "-- Táº¥t cáº£ --" else selected_industry

with st.sidebar.container():
    st.markdown('<div class="css-1d391kg-container">', unsafe_allow_html=True)
    st.markdown('<div class="css-1d391kg css-1d391kg-first">LÃª Há»¯u SÆ¡n Háº£i</div>', unsafe_allow_html=True)
    st.markdown('<div class="css-1d391kg css-1d391kg-second">ÄoÃ n Trung CÆ°á»ng</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” TÃ¬m theo tÃªn cÃ´ng ty", "âœï¸ TÃ¬m theo mÃ´ táº£", "Trá»±c quan hÃ³a dá»¯ liá»‡u", "ğŸ“‚ Dá»± Ä‘oÃ¡n theo file"])

with tab1:
    st.subheader("ğŸ” Nháº­p tÃªn cÃ´ng ty (vÃ­ dá»¥: FPT):")
    company_input = st.text_input("TÃªn cÃ´ng ty")
    if company_input:
        found_name, overview, result_df = suggest_by_company_name(company_input, top_n=top_n, industry_filter=industry_filter)
        if result_df is not None:
            st.success(f"âœ… TÃ¬m tháº¥y: **{found_name}**")
            st.markdown("**ğŸ“„ MÃ´ táº£ cÃ´ng ty:**")
            st.info(overview)
            st.markdown("ğŸ“ˆ **CÃ¡c cÃ´ng ty tÆ°Æ¡ng tá»±:**")
            for _, row in result_df.iterrows():
                common = get_common_keywords(overview, row['Company overview'])
                st.markdown(f"ğŸ”¹ **{row['Company Name']}** â€“ Ä‘iá»ƒm: {row['score']:.3f}")
                st.markdown(f"ğŸ—± Tá»« khÃ³a chung: {', '.join(common[:10])}")
                st.markdown("---")
            csv = result_df.to_csv(index=False).encode('utf-8')
            st.download_button("â¬‡ï¸ Táº£i danh sÃ¡ch CSV", csv, f"{found_name}_similar_companies.csv", "text/csv")
            st.subheader("ğŸ¤ Gá»£i Ã½ Ä‘á»‘i tÃ¡c tiá»m nÄƒng (khÃ¡c ngÃ nh)")
            partners = suggest_partners(company_input, top_n=5)
            if partners is not None:
                st.dataframe(partners, use_container_width=True)
            recommendation = predict_recommendation(found_name)
            st.subheader("ğŸ” Káº¿t quáº£ phÃ¢n loáº¡i:")
            st.write(f"CÃ´ng ty **{found_name}** Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ : **{recommendation}**")

with tab2:
    st.subheader("âœï¸ Nháº­p mÃ´ táº£ cÃ´ng ty hoáº·c lÄ©nh vá»±c báº¡n muá»‘n tÃ¬m:")
    description_input = st.text_area("VÃ­ dá»¥: CÃ´ng ty pháº§n má»m chuyÃªn vá» trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  dá»¯ liá»‡u lá»›n...")
    if description_input:
        results_desc = suggest_by_description(description_input, top_n=top_n)
        st.subheader("ğŸ“‹ Danh sÃ¡ch gá»£i Ã½ theo mÃ´ táº£:")
        st.dataframe(results_desc, use_container_width=True)
        csv_desc = results_desc.to_csv(index=False).encode('utf-8')
        st.download_button("â¬‡ï¸ Táº£i danh sÃ¡ch CSV", csv_desc, "description_based_suggestions.csv", "text/csv")

with tab3:
    st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch dá»¯ liá»‡u")
    plot_recommendation_distribution(df)
    plot_industry_distribution(df)


with tab4:
    uploaded_file = st.file_uploader("ğŸ“¤ Táº£i file CSV/XLSX", type=["csv", "xlsx"])
    if uploaded_file:
        # Äá»c file
        if uploaded_file.name.endswith(".csv"):
            df_input = pd.read_csv(uploaded_file)
        else:
            df_input = pd.read_excel(uploaded_file)

        st.subheader("ğŸ“„ Dá»¯ liá»‡u Ä‘Ã£ táº£i")
        st.dataframe(df_input)

        # CÃ¡c cá»™t cáº§n thiáº¿t
        required_columns = ['Company overview', 'Company industry', 'Training & learning', 'Salary & benefits']

        # Äáº£m báº£o cÃ³ Ä‘á»§ cÃ¡c cá»™t Ä‘áº§u vÃ o
        for col in required_columns:
            if col not in df_input.columns:
                df_input[col] = ""

        # LÃ m sáº¡ch dá»¯ liá»‡u giá»‘ng lÃºc huáº¥n luyá»‡n
        df_input['Company overview'] = df_input['Company overview'].astype(str).fillna("")
        df_input['Company industry'] = df_input['Company industry'].fillna("Unknown")
        df_input['Training & learning'] = pd.to_numeric(df_input['Training & learning'], errors='coerce')
        df_input['Salary & benefits'] = pd.to_numeric(df_input['Salary & benefits'], errors='coerce')

        df_input['Training & learning'] = df_input['Training & learning'].fillna(df_input['Training & learning'].median())
        df_input['Salary & benefits'] = df_input['Salary & benefits'].fillna(df_input['Salary & benefits'].median())

        # Dá»± Ä‘oÃ¡n
        try:
            features = df_input[required_columns]
            preds = xgboost_classifier.predict(features)
            df_input['Prediction'] = np.where(preds == 1, "Recommend", "Not Recommend")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi phÃ¢n loáº¡i: {e}")

        # Káº¿t quáº£
        st.subheader("ğŸ” Káº¿t quáº£ phÃ¢n loáº¡i")
        st.dataframe(df_input)

        # Táº£i xuá»‘ng káº¿t quáº£
        st.download_button("â¬‡ï¸ Táº£i káº¿t quáº£", df_input.to_csv(index=False).encode("utf-8"), "batch_predictions.csv")